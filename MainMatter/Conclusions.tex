\cleardoublepage
%
\phantomsection
%
%\addcontentsline{toc}{chapter}{Conclusions}
%
\chapter{Conclusions}
%
\markboth{Conclusions}{Conclusions}	% headings
%
\label{cap:conclusions}

In this chapter a summary of the work presented by this thesis and of the results of the tests performed on it will be provided. Finally, an overview on the possible future works, able to extend the \emph{Dynamic Checkpoint Rate Tuning} and the \emph{Reliam Resource Allocation Policy}, will be furnished.

\section{Conclusions}
This thesis presents our contribution to the mitigation of the reliability problem in HPC systems, which represents a matter of major concern with the advance in technology and popularity of such systems in a wide area of applications.

We firstly described the \emph{Dynamic Checkpoint Rate Tuning}, an application-aware checkpoint scheduler, whose objective relies in the maximization of the fault tolerance with utmost attention to its impact on the performance.

We provided the possibility for the user to set an upper bound $k$, defined as the tolerated overhead with respect to the non-faulty execution of the sole application code. The value of $k$ is considered during the checkpoint scheduling, based on the prediction of the checkpoint time, in order not to lower the desired application performance.
 
In the case of smaller sized problem applications, such approach resulted effective in all the tested levels of system criticality. For such kind of workload, setting a low value of $k$ (up to the 2\% of overhead) resulted \emph{safe} with respect to the performance counting, which continued to be only slightly undermined, even in highly critical systems (i.e. with failure rate equal to $10^{-3}$ failures per hour). In such case, \emph{restart time} showed a worsening of the performance of less than 2\% in the worse tested case\footnote{$k=0.02$, i.e. maximum tolerated overhead of 2\%.}, a weight halved already with $k=0.04$. Slightly different results have been achieved for bigger sized problems. In this scenario, tested with a minimum tolerated checkpoint overhead of $k=0.05$, we registered a negligible worsening of the performance given by restart time in averagely and highly reliable systems (i.e. systems with failure rate lower than $10^{-4}$ failures per hour), while an inversion of the trend has been observed for higher failure rates. In this case, lower values of $k$ led to a cumulative performance worsening higher than the one obtained with higher values of $k$. Considering $k=0.05$, for all three evaluated benchmarks, we observed a worse performance counting, due to \emph{restart time}, around values of failure rate equal to $10^{-4}$, where higher values of $k$ provided better performance. 
Conclusions deduced from such experiments are that, if, for smaller problem sizes, lower values of $k$ lead to lower worsening of the performance in all the realistic range of system criticality levels, for bigger problem sizes, an extra care is to be grant in the case of reliability critical system to not incur in high performance worsening caused by the time to recover from failures.

The second pillar this thesis has been built on is the design and implementation of the \emph{Reliam Resource Allocation Policy}. Such policy, periodically invoked, assigns a controller to each running application in order to iteratively adapt the allocation of the CPU quota to its computational need. Moreover, it makes binding decisions in order to improve application and system reliability. 

We firstly provided the experimental evaluation of the computation of the CPU quota allocation mechanism. Three practical scenarios have been described, analyzing the produced rise time, overshoot and settling time provided by the different tuning of the controlling parameters. It has been observed that, increasing the sole proportional contribution, a slow annulment of the error is achieved, favoring the minimization of the overshooting. This approach is to be preferred in the case of \emph{massively parallel systems}, in which the minimization of the CPU utilization is key for the overall performance. Conversely, the increase of the integral contribution significantly reduces the rise time, while enlarging the overshoot. A use case of such tuning might be represented by the willingness of prioritizing the execution performance of an application over the others. Lastly, increasing the derivative contribution in place of the integral one, resulted in the reduction of overshooting and a consequently small settling time, a desired behavior in the case of batch application, whose workload tend to slightly vary over time.

Finally, we evaluated the effectiveness of the reliability-aware decisions, by applying them to a simulated multi-node system. We observed that the use of the Reliam Resource Allocation Policy, promoting the binding with the most reliable processing units, favors the reduction in the number of occurred failure, hence, in the application total time. Moreover, it significantly lowers the \emph{acceleration factor} of the resources presenting the highest temperature, slowing down the degradation in terms of MTTF due to thermal stress.

\section{Future work}
The work, as proposed by this thesis, focuses on CPU based systems. A natural extension which needs to be integrated is the support for heterogeneous systems. As anticipated in {\hyperref[cap:stateofart]{Chapter 2}}, at the time of writing, a stable software tool able to perform checkpoints of GPU applications does not exist: when such technology will become available, the \emph{Dynamic Checkpoint Rate Tuning} might be integrated with a support in such regard. As for FPGA, a partnership with \emph{CeRICT (Centro Regionale Information Communication Technology)} is already in progress, to integrate the already existing \verb|libacre|, the library currently overseeing the checkpointing in the BarbequeRTRM, with a support on such technology. When this work will be finalized, FPGA checkpointing might be included in the \emph{Dynamic Checkpoint Rate Tuning}.

Moreover, the current implementation of the \emph{Dynamic Checkpoint Rate Tuning} presents a limitation represented by the degradation of the performance of big problem sized workload in case of unreliable systems. Since failure rate is reasonable to change over time, the initial choice of $k$ might not be suitable for the entire execution time of the application. In this regard, a possible future work is represented by the integration in the framework of a run time and/or input profiling of the application workload, able, given the reliability information provided by the \verb|libhwrel|, to predict at which failure rate the value of $k$ stops being proportional to the gain in performance. In this way, it will be possible for the \emph{Dynamic Checkpoint Rate Tuning} to modify accordingly the value of $k$, in order not to lose the performance goal.

Another natural continuation of our project is represented by the support of custom accelerators in the \emph{Reliam Resource Allocation Policy}. At the time of writing, it is not possible to adapt the concept of \emph{quota} to these technologies, nevertheless, it is still possible to apply the proposed reliability-aware decisions of the policy at processing unit level, in order to contrast the wear out of such hardware components.